# -*- coding: utf-8 -*-
"""NER_Test_Code.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vPbF5XOzNpBEyhm1Ap_HCnswPeBjwyI1


!pip install transformers #huggingface 패키지

!git lfs install
!git clone https://huggingface.co/keonju/korean_disease_ner  # 모델 다운로드 코드 -> 안하면 밑에 코드로 다운로드 받아도 됨됨

"""
# Class로 구현하기
from transformers import AutoTokenizer, AutoModelForTokenClassification # 토크나이저와 모델 불러오는 코드
import torch
class ner():

  def __init__(self): # 토크나이저랑 모델 저장 -> git으로 받았으면 모델 경로로 바꿔주면됨(안바꾸면 네트워크에서 다운로드됨)
    self.tokenizer = AutoTokenizer.from_pretrained("./korean_disease_ner")
    self.model = AutoModelForTokenClassification.from_pretrained("./korean_disease_ner")

  def __call__(self, input):
    token = self.tokenizer(input, return_tensors='pt') # 토크나이저
    input_words = self.tokenizer.tokenize(input) # 토큰화된 문장 결과 ['나','##는', '오늘', '아들','##이'...]
    with torch.no_grad(): #파이토치 test
      logits = self.model(**token).logits # 확률 반환
    predictions = torch.argmax(logits, dim=2) # 확률 제일 높은 값 매칭
    predicted_token_class = [self.model.config.id2label[t.item()] for t in predictions[0]][1:-1] # id랑 label 매칭
    new_token = [] # 분할되었을 때 조사에 할당된 label은 제거한 것 저장하기 위해 만든 리스트
    input_list = input.split(' ') #띄어쓰기 기준으로 텍스트 출력하기 위해 split
    target_list = []
    for w in range(len(input_words)): # 조사에 할당된 label제거
      if '#' not in input_words[w]: # 조사가 없으면
        if predicted_token_class[w] == 'O': #'O'는 무의미한 label
          pass #'O' 빼고 저장
        else:
          target_list.append(input_words[w])
          new_token.append(predicted_token_class[w]) #'label 앞뒤로 괄호'

    return {'type':new_token,'target':target_list,'fullText':input}

# a = ner()
# print(a('나는 오늘 아들이 보고싶어요'))
